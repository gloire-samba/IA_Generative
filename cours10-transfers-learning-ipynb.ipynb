{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":320111,"sourceType":"datasetVersion","datasetId":134715}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Installation des bibliothÃ¨ques nÃ©cessaires\n!pip install peft\n!pip install evaluate\n\n!pip install -U transformers datasets accelerate","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-19T20:31:54.091301Z","iopub.execute_input":"2025-11-19T20:31:54.091572Z","iopub.status.idle":"2025-11-19T20:33:34.389776Z","shell.execute_reply.started":"2025-11-19T20:31:54.091551Z","shell.execute_reply":"2025-11-19T20:33:34.388824Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.16.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from peft) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from peft) (25.0)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft) (7.1.3)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from peft) (6.0.3)\nRequirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from peft) (2.6.0+cu124)\nRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from peft) (4.53.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from peft) (4.67.1)\nRequirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from peft) (1.9.0)\nRequirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from peft) (0.5.3)\nRequirement already satisfied: huggingface_hub>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from peft) (0.36.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (3.20.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (2025.10.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (2.32.5)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (1.2.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->peft) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->peft) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->peft) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->peft) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->peft) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->peft) (2.4.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.1.6)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.13.0->peft)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.13.0->peft)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.13.0->peft)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.13.0->peft)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.13.0->peft)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.13.0->peft)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.13.0->peft)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.13.0->peft)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.13.0->peft)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.13.0->peft)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->peft) (2025.11.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->peft) (0.21.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.3)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->peft) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->peft) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->peft) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->peft) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->peft) (2024.2.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (2025.10.5)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->peft) (2024.2.0)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m86.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m89.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\nCollecting evaluate\n  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.4.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.4.0)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.3)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.5)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.6.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.18)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.10.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.36.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (25.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.20.0)\nCollecting pyarrow>=21.0.0 (from datasets>=2.0.0->evaluate)\n  Downloading pyarrow-22.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\nRequirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (0.28.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.3)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.13.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.2.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.10.5)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.22.0)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (4.11.0)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets>=2.0.0->evaluate) (0.16.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1.0.0->datasets>=2.0.0->evaluate) (1.3.1)\nDownloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyarrow-22.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (47.7 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pyarrow, evaluate\n  Attempting uninstall: pyarrow\n    Found existing installation: pyarrow 19.0.1\n    Uninstalling pyarrow-19.0.1:\n      Successfully uninstalled pyarrow-19.0.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\npylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\ncudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\ncudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed evaluate-0.4.6 pyarrow-22.0.0\nRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.3)\nCollecting transformers\n  Downloading transformers-4.57.1-py3-none-any.whl.metadata (43 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (4.4.1)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.9.0)\nCollecting accelerate\n  Downloading accelerate-1.11.0-py3-none-any.whl.metadata (19 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.20.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.36.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.3)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2025.11.3)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.5)\nCollecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n  Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (22.0.0)\nRequirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.4.0)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.6.0)\nRequirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.18)\nRequirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.10.0)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (7.1.3)\nRequirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets) (4.11.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets) (2025.10.5)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\nRequirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets) (3.11)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nDownloading transformers-4.57.1-py3-none-any.whl (12.0 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading accelerate-1.11.0-py3-none-any.whl (375 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m375.8/375.8 kB\u001b[0m \u001b[31m491.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: tokenizers, transformers, accelerate\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.21.2\n    Uninstalling tokenizers-0.21.2:\n      Successfully uninstalled tokenizers-0.21.2\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.53.3\n    Uninstalling transformers-4.53.3:\n      Successfully uninstalled transformers-4.53.3\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 1.9.0\n    Uninstalling accelerate-1.9.0:\n      Successfully uninstalled accelerate-1.9.0\nSuccessfully installed accelerate-1.11.0 tokenizers-0.22.1 transformers-4.57.1\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# Importation des BibliothÃ¨ques","metadata":{}},{"cell_type":"code","source":"# Importation des bibliothÃ¨ques essentielles pour le traitement des donnÃ©es et le machine learning\nimport numpy as np\nimport torch\nimport pandas as pd\nfrom datasets import Dataset\nfrom sklearn.model_selection import train_test_split\nimport os\n\n\n\n# BibliothÃ¨que pour l'Ã©valuation des modÃ¨les\nimport evaluate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T20:33:34.391323Z","iopub.execute_input":"2025-11-19T20:33:34.391559Z","iopub.status.idle":"2025-11-19T20:33:59.106513Z","shell.execute_reply.started":"2025-11-19T20:33:34.391534Z","shell.execute_reply":"2025-11-19T20:33:59.105749Z"}},"outputs":[{"name":"stderr","text":"2025-11-19 20:33:44.709490: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1763584424.903890      48 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1763584424.961037      48 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"}],"execution_count":2},{"cell_type":"markdown","source":"# Chargement des donnÃ©es","metadata":{}},{"cell_type":"code","source":"\n# ğŸ“ Dossier du dataset IMDB sur Kaggle\nbase = \"/kaggle/input/imdb-dataset-of-50k-movie-reviews\"\n\n# ğŸ“„ Fichier principal\ndata_path = os.path.join(base, \"IMDB Dataset.csv\")\n\n# âœ… VÃ©rification\nprint(\"ğŸ“‚ Contenu du dossier :\", os.listdir(base))\nprint(\"ğŸ“„ Chargement du fichier :\", data_path)\n\n# ğŸ”¹ Chargement du dataset\ndf = pd.read_csv(data_path)\n\nprint(\"\\nâœ… DonnÃ©es chargÃ©es avec succÃ¨s !\")\nprint(\"ğŸ“Š Dimensions :\", df.shape)\nprint(\"ğŸ“ˆ Colonnes :\", list(df.columns))\nprint(\"\\nAperÃ§u :\")\nprint(df.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T20:33:59.107234Z","iopub.execute_input":"2025-11-19T20:33:59.107686Z","iopub.status.idle":"2025-11-19T20:34:00.312817Z","shell.execute_reply.started":"2025-11-19T20:33:59.107666Z","shell.execute_reply":"2025-11-19T20:34:00.312153Z"}},"outputs":[{"name":"stdout","text":"ğŸ“‚ Contenu du dossier : ['IMDB Dataset.csv']\nğŸ“„ Chargement du fichier : /kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\n\nâœ… DonnÃ©es chargÃ©es avec succÃ¨s !\nğŸ“Š Dimensions : (50000, 2)\nğŸ“ˆ Colonnes : ['review', 'sentiment']\n\nAperÃ§u :\n                                              review sentiment\n0  One of the other reviewers has mentioned that ...  positive\n1  A wonderful little production. <br /><br />The...  positive\n2  I thought this was a wonderful way to spend ti...  positive\n3  Basically there's a family where a little boy ...  negative\n4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Conversion des Ã©tiquettes en format numÃ©rique\ndf['label'] = df['sentiment'].map({'positive': 1, 'negative': 0})\ndf = df.drop(['sentiment'], axis=1) \ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T20:34:00.314506Z","iopub.execute_input":"2025-11-19T20:34:00.314805Z","iopub.status.idle":"2025-11-19T20:34:00.337895Z","shell.execute_reply.started":"2025-11-19T20:34:00.314786Z","shell.execute_reply":"2025-11-19T20:34:00.337339Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                              review  label\n0  One of the other reviewers has mentioned that ...      1\n1  A wonderful little production. <br /><br />The...      1\n2  I thought this was a wonderful way to spend ti...      1\n3  Basically there's a family where a little boy ...      0\n4  Petter Mattei's \"Love in the Time of Money\" is...      1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>One of the other reviewers has mentioned that ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I thought this was a wonderful way to spend ti...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Basically there's a family where a little boy ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"# SÃ©parer les donnÃ©es en ensembles d'entraÃ®nement et de test\ntrain_df, test_df = train_test_split(df, test_size=0.2, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T20:34:00.338436Z","iopub.execute_input":"2025-11-19T20:34:00.338651Z","iopub.status.idle":"2025-11-19T20:34:00.346117Z","shell.execute_reply.started":"2025-11-19T20:34:00.338627Z","shell.execute_reply":"2025-11-19T20:34:00.345405Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# SÃ©lectionner un sous-ensemble alÃ©atoire de N Ã©chantillons pour l'entraÃ®nement et le test\nN = 1000\ntrain_subset = train_df.sample(n=N, random_state=42)\ntest_subset = test_df.sample(n=N, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T20:34:00.346804Z","iopub.execute_input":"2025-11-19T20:34:00.347029Z","iopub.status.idle":"2025-11-19T20:34:00.361652Z","shell.execute_reply.started":"2025-11-19T20:34:00.347004Z","shell.execute_reply":"2025-11-19T20:34:00.360962Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# CrÃ©er les datasets Hugging Face\ntrain_dataset = Dataset.from_pandas(train_subset)\ntest_dataset = Dataset.from_pandas(test_subset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T20:34:00.362291Z","iopub.execute_input":"2025-11-19T20:34:00.362623Z","iopub.status.idle":"2025-11-19T20:34:00.393480Z","shell.execute_reply.started":"2025-11-19T20:34:00.362605Z","shell.execute_reply":"2025-11-19T20:34:00.392819Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"train_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T20:34:00.394258Z","iopub.execute_input":"2025-11-19T20:34:00.394493Z","iopub.status.idle":"2025-11-19T20:34:00.399098Z","shell.execute_reply.started":"2025-11-19T20:34:00.394469Z","shell.execute_reply":"2025-11-19T20:34:00.398556Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['review', 'label', '__index_level_0__'],\n    num_rows: 1000\n})"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"test_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T20:34:00.399812Z","iopub.execute_input":"2025-11-19T20:34:00.400060Z","iopub.status.idle":"2025-11-19T20:34:00.412658Z","shell.execute_reply.started":"2025-11-19T20:34:00.400039Z","shell.execute_reply":"2025-11-19T20:34:00.412000Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['review', 'label', '__index_level_0__'],\n    num_rows: 1000\n})"},"metadata":{}}],"execution_count":9},{"cell_type":"markdown","source":"# Finetuning complet","metadata":{}},{"cell_type":"code","source":"import torch\n# Importe PyTorch, une bibliothÃ¨que pour les rÃ©seaux de neurones profonds et l'apprentissage automatique.\n\nimport pandas as pd\n# Importe pandas, une bibliothÃ¨que pour la manipulation et l'analyse de donnÃ©es, souvent utilisÃ©e pour manipuler des tableaux de donnÃ©es.\n\nfrom datasets import Dataset, DatasetDict\n# Importe 'Dataset' et 'DatasetDict' de la bibliothÃ¨que 'datasets' de Hugging Face, utilisÃ©s pour gÃ©rer et prÃ©parer des ensembles de donnÃ©es pour l'entraÃ®nement de modÃ¨les.\n\nfrom transformers import DistilBertTokenizer, DistilBertForSequenceClassification, TrainingArguments, Trainer\n# Importe plusieurs classes de la bibliothÃ¨que 'transformers' de Hugging Face:\n# - DistilBertTokenizer : pour convertir du texte en tokens comprÃ©hensibles par DistilBERT.\n# - DistilBertForSequenceClassification : une version de DistilBERT prÃ©parÃ©e pour la classification de sÃ©quences (par exemple, classification de texte).\n# - TrainingArguments : pour configurer les paramÃ¨tres d'entraÃ®nement.\n# - Trainer : pour orchestrer le processus d'entraÃ®nement du modÃ¨le.\n\nimport torch.optim as optim\n# Importe le sous-module 'optim' de PyTorch, qui contient divers algorithmes d'optimisation utilisÃ©s pour mettre Ã  jour les poids du rÃ©seau pendant l'entraÃ®nement, tels que SGD, Adam, etc.\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T20:34:00.415200Z","iopub.execute_input":"2025-11-19T20:34:00.415582Z","iopub.status.idle":"2025-11-19T20:34:02.129758Z","shell.execute_reply.started":"2025-11-19T20:34:00.415566Z","shell.execute_reply":"2025-11-19T20:34:02.129185Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# ParamÃ¨tres d'entraÃ®nement\nmodel_checkpoint = \"distilbert-base-uncased\"  # ModÃ¨le distilbert prÃ©-entraÃ®nÃ©\nlr = 2e-5  # Taux d'apprentissage\nbatch_size = 8  # Taille du lot\nnum_epochs = 3  # Nombre d'Ã©poques","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T20:34:02.130457Z","iopub.execute_input":"2025-11-19T20:34:02.130659Z","iopub.status.idle":"2025-11-19T20:34:02.134703Z","shell.execute_reply.started":"2025-11-19T20:34:02.130643Z","shell.execute_reply":"2025-11-19T20:34:02.133975Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# Charger le tokenizer prÃ©-entraÃ®nÃ©\ntokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n\n# Convertir les colonnes en listes Python (simple)\ntrain_texts = [str(x) for x in train_dataset[\"review\"]]\ntest_texts = [str(x) for x in test_dataset[\"review\"]]\n\n# Tokenization correcte\ntrain_encodings = tokenizer(train_texts, truncation=True, padding=True, return_tensors='pt')\ntest_encodings = tokenizer(test_texts, truncation=True, padding=True, return_tensors='pt')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T20:34:02.135464Z","iopub.execute_input":"2025-11-19T20:34:02.135679Z","iopub.status.idle":"2025-11-19T20:34:10.610335Z","shell.execute_reply.started":"2025-11-19T20:34:02.135664Z","shell.execute_reply":"2025-11-19T20:34:10.609725Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9df47ac8277b4066a21d990510c03f6b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c67f3d1baf4749279a690deee1f973f6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"890edb1b5f8e49dead17ec8162ffa396"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a7c87c8234448fb9fa98077173a16f2"}},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"# Ã‰tape 2 : CrÃ©ation des datasets PyTorch\n\ntrain_labels = train_subset[\"label\"].tolist()\n\ntrain_datasetb = Dataset.from_dict({\n    # 'input_ids' : Contient les identifiants de tokens obtenus aprÃ¨s le processus de tokenisation du texte. \n    # Ces identifiants sont nÃ©cessaires pour que le modÃ¨le comprenne et traite le texte.\n    'input_ids': train_encodings['input_ids'],\n    # 'attention_mask' : Un masque d'attention qui indique au modÃ¨le quels tokens dans 'input_ids' sont significatifs \n    # (c'est-Ã -dire non-padding) et doivent Ãªtre pris en compte lors du traitement.\n    'attention_mask': train_encodings['attention_mask'],\n    # 'labels' : Les Ã©tiquettes associÃ©es Ã  chaque exemple d'entraÃ®nement. Ces Ã©tiquettes sont utilisÃ©es pour l'apprentissage supervisÃ©,\n    # oÃ¹ le modÃ¨le apprend Ã  associer les entrÃ©es Ã  ces Ã©tiquettes correctes.\n    # 'torch.tensor()' est utilisÃ© pour convertir la liste des Ã©tiquettes en tensor PyTorch, \n    # ce qui est nÃ©cessaire pour le traitement avec PyTorch.\n    'labels': torch.tensor(train_labels)\n})\n\n\ntest_labels = test_subset[\"label\"].tolist()\n\ntest_datasetb = Dataset.from_dict({\n    'input_ids': test_encodings['input_ids'],\n    'attention_mask': test_encodings['attention_mask'],\n    'labels': torch.tensor(test_labels)\n})\n\n# CrÃ©ation d'un DatasetDict\ndatasetb = DatasetDict({\n    'train': train_datasetb,\n    'test': test_datasetb\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T20:34:10.611090Z","iopub.execute_input":"2025-11-19T20:34:10.611320Z","iopub.status.idle":"2025-11-19T20:34:10.708058Z","shell.execute_reply.started":"2025-11-19T20:34:10.611303Z","shell.execute_reply":"2025-11-19T20:34:10.707448Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# CrÃ©ation d'un modÃ¨le de classification de sÃ©quences basÃ© sur DistilBERT\nmodel = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T20:34:10.708774Z","iopub.execute_input":"2025-11-19T20:34:10.709000Z","iopub.status.idle":"2025-11-19T20:34:12.194552Z","shell.execute_reply.started":"2025-11-19T20:34:10.708984Z","shell.execute_reply":"2025-11-19T20:34:12.193817Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49753284961b44ca916b631aea803ca1"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# Affichage du nombre de paramÃ¨tres du modÃ¨le\nnum_params = sum(p.numel() for p in model.parameters())\nprint(f\"Nombre de paramÃ¨tres du modÃ¨le : {num_params}\")\n\n# Afficher l'architecture du modÃ¨le BERT\nprint(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T20:34:12.195397Z","iopub.execute_input":"2025-11-19T20:34:12.195635Z","iopub.status.idle":"2025-11-19T20:34:12.200996Z","shell.execute_reply.started":"2025-11-19T20:34:12.195617Z","shell.execute_reply":"2025-11-19T20:34:12.200360Z"}},"outputs":[{"name":"stdout","text":"Nombre de paramÃ¨tres du modÃ¨le : 66955010\nDistilBertForSequenceClassification(\n  (distilbert): DistilBertModel(\n    (embeddings): Embeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (transformer): Transformer(\n      (layer): ModuleList(\n        (0-5): 6 x TransformerBlock(\n          (attention): DistilBertSdpaAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n            (activation): GELUActivation()\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n      )\n    )\n  )\n  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n  (classifier): Linear(in_features=768, out_features=2, bias=True)\n  (dropout): Dropout(p=0.2, inplace=False)\n)\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# Ã‰tape 4 : DÃ©finition des paramÃ¨tres d'entraÃ®nement\n# Configuration de l'optimiseur pour l'entraÃ®nement du modÃ¨le\noptimizer = optim.AdamW(model.parameters(), lr=lr)\n# DÃ©finition de la fonction de perte pour l'entraÃ®nement du modÃ¨le\nloss_fn = torch.nn.CrossEntropyLoss()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T20:34:12.201609Z","iopub.execute_input":"2025-11-19T20:34:12.201877Z","iopub.status.idle":"2025-11-19T20:34:12.217246Z","shell.execute_reply.started":"2025-11-19T20:34:12.201852Z","shell.execute_reply":"2025-11-19T20:34:12.216620Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# Importer la mÃ©trique pour l'Ã©valuation\naccuracy = evaluate.load(\"accuracy\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T20:34:12.217954Z","iopub.execute_input":"2025-11-19T20:34:12.218140Z","iopub.status.idle":"2025-11-19T20:34:12.810435Z","shell.execute_reply.started":"2025-11-19T20:34:12.218127Z","shell.execute_reply":"2025-11-19T20:34:12.809799Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e7722b511a6b42f3af6d10f88448d36f"}},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"def compute_metrics(p):\n    predictions, labels = p\n    predictions = np.argmax(predictions, axis=1)\n    accuracy_value = accuracy.compute(predictions=predictions, references=labels)[\"accuracy\"]\n    return {\"accuracy\": accuracy_value}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T20:34:12.811219Z","iopub.execute_input":"2025-11-19T20:34:12.811752Z","iopub.status.idle":"2025-11-19T20:34:12.815517Z","shell.execute_reply.started":"2025-11-19T20:34:12.811734Z","shell.execute_reply":"2025-11-19T20:34:12.814746Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# DÃ©finir la correspondance entre les identifiants de classe et les Ã©tiquettes\nid2label = {0: \"NÃ©gatif\", 1: \"Positif\"}\nlabel2id = {\"NÃ©gatif\": 0, \"Positif\": 1}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T20:34:12.816180Z","iopub.execute_input":"2025-11-19T20:34:12.816370Z","iopub.status.idle":"2025-11-19T20:34:12.832059Z","shell.execute_reply.started":"2025-11-19T20:34:12.816356Z","shell.execute_reply":"2025-11-19T20:34:12.831451Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"liste_texte = [\n    \"This movie was a masterpiece.\",\n    \"I was blown away by the acting.\",\n    \"It's a classic that everyone should watch.\",\n    \"The plot was confusing and hard to follow.\",\n    \"The special effects were top-notch.\",\n    \"I couldn't stop laughing throughout the movie.\",\n    \"The soundtrack was incredible.\",\n    \"It's a total waste of time.\",\n    \"I'm still thinking about that ending.\",\n    \"I wouldn't recommend it to anyone.\"\n]\n\n\nprint(\"PrÃ©dictions du modÃ¨le non entraÃ®nÃ©:\")\nprint(\"-------------------------------------\")\nfor texte in liste_texte:\n    # Tokenizer le texte\n    inputs = tokenizer.encode(texte, return_tensors=\"pt\")\n    # Calculer les logits\n    logits = model(inputs).logits\n    # Convertir les logits en Ã©tiquette\n    predictions = torch.argmax(logits)\n\n    print(texte + \" - \" + id2label[predictions.tolist()])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T20:34:12.832723Z","iopub.execute_input":"2025-11-19T20:34:12.832934Z","iopub.status.idle":"2025-11-19T20:34:13.221373Z","shell.execute_reply.started":"2025-11-19T20:34:12.832912Z","shell.execute_reply":"2025-11-19T20:34:13.220551Z"}},"outputs":[{"name":"stdout","text":"PrÃ©dictions du modÃ¨le non entraÃ®nÃ©:\n-------------------------------------\nThis movie was a masterpiece. - Positif\nI was blown away by the acting. - Positif\nIt's a classic that everyone should watch. - Positif\nThe plot was confusing and hard to follow. - NÃ©gatif\nThe special effects were top-notch. - Positif\nI couldn't stop laughing throughout the movie. - NÃ©gatif\nThe soundtrack was incredible. - Positif\nIt's a total waste of time. - Positif\nI'm still thinking about that ending. - Positif\nI wouldn't recommend it to anyone. - Positif\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"# Ã‰tape 5 : DÃ©finition des arguments d'entraÃ®nement avec Transformers\n\ntraining_args = TrainingArguments(\n    output_dir=model_checkpoint + \"-fullfinetuned-text-classification\",# Le rÃ©pertoire oÃ¹ les rÃ©sultats de l'entraÃ®nement seront sauvegardÃ©s\n    learning_rate=lr,# Taux d'apprentissage pour l'optimisation du modÃ¨le\n    per_device_train_batch_size=batch_size,# Taille du lot d'entraÃ®nement par pÃ©riphÃ©rique (GPU ou CPU)\n    per_device_eval_batch_size=batch_size,# Taille du lot d'Ã©valuation par pÃ©riphÃ©rique (GPU ou CPU)\n    num_train_epochs=num_epochs, # Nombre d'Ã©poques d'entraÃ®nement (combien de fois le modÃ¨le parcourt l'ensemble de donnÃ©es)\n    weight_decay=0.01, # Terme de rÃ©gularisation pour contrÃ´ler le poids de la pÃ©nalisation dans la fonction de perte\n\n    eval_strategy=\"epoch\",   # â¬…ï¸ nouveau paramÃ¨tre # StratÃ©gie d'Ã©valuation, ici \"epoch\" signifie Ã©valuer Ã  la fin de chaque Ã©poque\n    save_strategy=\"epoch\",   # â¬…ï¸ inchangÃ© # StratÃ©gie de sauvegarde du modÃ¨le, ici \"epoch\" signifie sauvegarder le modÃ¨le Ã  la fin de chaque Ã©poque\n    load_best_model_at_end = True, # Charger le meilleur modÃ¨le Ã  la fin de l'entraÃ®nement\n    report_to=\"none\"\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T20:40:53.000074Z","iopub.execute_input":"2025-11-19T20:40:53.000795Z","iopub.status.idle":"2025-11-19T20:40:53.028068Z","shell.execute_reply.started":"2025-11-19T20:40:53.000767Z","shell.execute_reply":"2025-11-19T20:40:53.027522Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"# Ã‰tape 6 : EntraÃ®nement du modÃ¨le avec Trainer de Transformers\ntrainerfull = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=datasetb['train'],\n    eval_dataset=datasetb['test'],\n    compute_metrics=compute_metrics  # Utiliser la fonction de calcul des mÃ©triques\n\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T20:40:58.253299Z","iopub.execute_input":"2025-11-19T20:40:58.254064Z","iopub.status.idle":"2025-11-19T20:40:58.266359Z","shell.execute_reply.started":"2025-11-19T20:40:58.254029Z","shell.execute_reply":"2025-11-19T20:40:58.265656Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"# EntraÃ®nement du modÃ¨le\ntrainerfull.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T20:41:01.539563Z","iopub.execute_input":"2025-11-19T20:41:01.540328Z","iopub.status.idle":"2025-11-19T20:43:20.974590Z","shell.execute_reply.started":"2025-11-19T20:41:01.540299Z","shell.execute_reply":"2025-11-19T20:43:20.973973Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='375' max='375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [375/375 02:18, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.621213</td>\n      <td>0.877000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>0.507758</td>\n      <td>0.898000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>0.530897</td>\n      <td>0.891000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=375, training_loss=0.12051556396484375, metrics={'train_runtime': 138.9141, 'train_samples_per_second': 21.596, 'train_steps_per_second': 2.7, 'total_flos': 397402195968000.0, 'train_loss': 0.12051556396484375, 'epoch': 3.0})"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"# Sauvegarde du modÃ¨le\ntrainerfull.save_model(\"trainer_full\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T20:43:35.160293Z","iopub.execute_input":"2025-11-19T20:43:35.160576Z","iopub.status.idle":"2025-11-19T20:43:35.790376Z","shell.execute_reply.started":"2025-11-19T20:43:35.160554Z","shell.execute_reply":"2025-11-19T20:43:35.789621Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"import torch\n\n# 1. DÃ©finir le bon pÃ©riphÃ©rique (device)\n# Sur Kaggle avec GPU, ce sera \"cuda\". Sinon \"cpu\".\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"Le modÃ¨le sera exÃ©cutÃ© sur : {device}\")\n\n# 2. Sauvegarde du modÃ¨le (inchangÃ©)\ntrainerfull.save_model(\"trainer_full\")\n\n# 3. Passer le modÃ¨le sur le bon pÃ©riphÃ©rique (cuda)\nmodel.to(device)\n\n# 4. Afficher les prÃ©dictions\nprint(\"PrÃ©dictions du modÃ¨le entraÃ®nÃ© :\")\nprint(\"---------------------------------\")\n\n# Parcourir la liste des textes Ã  prÃ©dire\nfor texte in liste_texte:\n    # Tokenizer le texte ET l'envoyer sur le mÃªme pÃ©riphÃ©rique que le modÃ¨le\n    inputs = tokenizer.encode(texte, return_tensors=\"pt\").to(device) # <--- Ici, on utilise 'device' (cuda)\n\n    # Obtenir les logits\n    with torch.no_grad(): # Optionnel mais recommandÃ© pour l'infÃ©rence (Ã©conomise la mÃ©moire)\n        logits = model(inputs).logits\n\n    # PrÃ©dire la classe\n    predictions = torch.max(logits, 1).indices\n\n    # Afficher le rÃ©sultat\n    print(texte + \" - \" + id2label[predictions.tolist()[0]])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T20:48:51.802129Z","iopub.execute_input":"2025-11-19T20:48:51.802788Z","iopub.status.idle":"2025-11-19T20:48:52.737110Z","shell.execute_reply.started":"2025-11-19T20:48:51.802761Z","shell.execute_reply":"2025-11-19T20:48:52.736482Z"}},"outputs":[{"name":"stdout","text":"Le modÃ¨le sera exÃ©cutÃ© sur : cuda\nPrÃ©dictions du modÃ¨le entraÃ®nÃ© :\n---------------------------------\nThis movie was a masterpiece. - Positif\nI was blown away by the acting. - NÃ©gatif\nIt's a classic that everyone should watch. - Positif\nThe plot was confusing and hard to follow. - NÃ©gatif\nThe special effects were top-notch. - Positif\nI couldn't stop laughing throughout the movie. - NÃ©gatif\nThe soundtrack was incredible. - Positif\nIt's a total waste of time. - NÃ©gatif\nI'm still thinking about that ending. - NÃ©gatif\nI wouldn't recommend it to anyone. - NÃ©gatif\n","output_type":"stream"}],"execution_count":32},{"cell_type":"markdown","source":"# Layer freezing finetuning","metadata":{}},{"cell_type":"code","source":"# Charger le tokenizer\ntokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n\n# --- CORRECTION ICI ---\n# On extrait explicitement les textes et on force la conversion en string (str)\n# pour Ã©viter les erreurs si une ligne est vide ou mal formatÃ©e.\ntrain_texts = [str(x) for x in train_dataset['review']]\ntest_texts = [str(x) for x in test_dataset['review']]\n\n# Maintenant, on passe ces listes propres au tokenizer\ntrain_encodings = tokenizer(train_texts, truncation=True, padding=True, return_tensors='pt')\ntest_encodings = tokenizer(test_texts, truncation=True, padding=True, return_tensors='pt')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T20:50:31.067226Z","iopub.execute_input":"2025-11-19T20:50:31.067966Z","iopub.status.idle":"2025-11-19T20:50:38.946078Z","shell.execute_reply.started":"2025-11-19T20:50:31.067929Z","shell.execute_reply":"2025-11-19T20:50:38.945265Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"train_datasetb = Dataset.from_dict({\n    'input_ids': train_encodings['input_ids'],\n    'attention_mask': train_encodings['attention_mask'],\n    'labels': torch.tensor(train_dataset['label'])\n})\n\ntest_datasetb = Dataset.from_dict({\n    'input_ids': test_encodings['input_ids'],\n    'attention_mask': test_encodings['attention_mask'],\n    'labels': torch.tensor(test_dataset['label'])\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T20:50:40.132812Z","iopub.execute_input":"2025-11-19T20:50:40.133108Z","iopub.status.idle":"2025-11-19T20:50:40.397360Z","shell.execute_reply.started":"2025-11-19T20:50:40.133088Z","shell.execute_reply":"2025-11-19T20:50:40.396516Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"# ModÃ¨le DistilBERT pour la classification de sÃ©quences\nmodelf = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T20:50:43.314173Z","iopub.execute_input":"2025-11-19T20:50:43.314933Z","iopub.status.idle":"2025-11-19T20:50:43.440723Z","shell.execute_reply.started":"2025-11-19T20:50:43.314907Z","shell.execute_reply":"2025-11-19T20:50:43.439955Z"}},"outputs":[{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"# Geler certaines couches du modÃ¨le\nfor param in modelf.base_model.parameters():\n    param.requires_grad = False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T20:50:46.434616Z","iopub.execute_input":"2025-11-19T20:50:46.434929Z","iopub.status.idle":"2025-11-19T20:50:46.439392Z","shell.execute_reply.started":"2025-11-19T20:50:46.434905Z","shell.execute_reply":"2025-11-19T20:50:46.438566Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"from transformers import TrainingArguments\n\n# DÃ©finir les arguments d'entraÃ®nement pour le Trainer de Hugging Face\ntraining_args = TrainingArguments(\n    # RÃ©pertoire oÃ¹ les rÃ©sultats d'entraÃ®nement (modÃ¨les, configurations, etc.) seront sauvegardÃ©s.\n    output_dir=\"./freezdistilbert_finetuned\",\n\n    # Nombre d'exemples par lot (batch) pour l'entraÃ®nement, dÃ©fini pour chaque pÃ©riphÃ©rique (GPU/CPU).\n    per_device_train_batch_size=8,\n    # Nombre d'exemples par lot pour l'Ã©valuation, dÃ©fini pour chaque pÃ©riphÃ©rique.\n    per_device_eval_batch_size=8,\n\n    # --- CORRECTION ICI ---\n    # \"evaluation_strategy\" est devenu \"eval_strategy\"\n    # StratÃ©gie d'Ã©valuation Ã  utiliser. Ici, \"steps\" signifie que l'Ã©valuation aura lieu Ã  intervalles rÃ©guliers de pas d'entraÃ®nement.\n    eval_strategy=\"steps\",\n\n    # FrÃ©quence d'Ã©valuation et de sauvegarde\n    # Nombre de pas d'entraÃ®nement Ã  effectuer avant de rÃ©aliser une Ã©valuation.\n    eval_steps=100,\n    # Nombre de pas d'entraÃ®nement aprÃ¨s lesquels le modÃ¨le sera sauvegardÃ©.\n    save_steps=100,\n\n    # Nombre d'Ã©poques\n    # Nombre total d'Ã©poques d'entraÃ®nement Ã  rÃ©aliser.\n    num_train_epochs=3,\n    # Taux d'apprentissage initial Ã  utiliser pour l'optimiseur\n    learning_rate=2e-5,\n    # Limite du nombre total de sauvegardes de checkpoints Ã  conserver. \n    # Ici, seul le checkpoint le plus rÃ©cent sera conservÃ©\n    save_total_limit=1,\n    \n    # Pour Ã©viter l'erreur wandb rencontrÃ©e prÃ©cÃ©demment\n    report_to=\"none\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T20:57:10.672395Z","iopub.execute_input":"2025-11-19T20:57:10.672707Z","iopub.status.idle":"2025-11-19T20:57:10.700873Z","shell.execute_reply.started":"2025-11-19T20:57:10.672668Z","shell.execute_reply":"2025-11-19T20:57:10.699888Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"# Importer la mÃ©trique d'exactitude pour l'Ã©valuation\n\naccuracy = evaluate.load(\"accuracy\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T20:57:14.142865Z","iopub.execute_input":"2025-11-19T20:57:14.143144Z","iopub.status.idle":"2025-11-19T20:57:14.560527Z","shell.execute_reply.started":"2025-11-19T20:57:14.143122Z","shell.execute_reply":"2025-11-19T20:57:14.559962Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"# Fonction pour calculer l'exactitude\ndef compute_metrics(p):\n    predictions, labels = p\n    predictions = np.argmax(predictions, axis=1)\n    \n    # Calcul de l'exactitude\n    accuracy = np.mean(predictions == labels)\n\n    return {\"accuracy\": accuracy}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T20:57:17.595231Z","iopub.execute_input":"2025-11-19T20:57:17.595748Z","iopub.status.idle":"2025-11-19T20:57:17.599800Z","shell.execute_reply.started":"2025-11-19T20:57:17.595713Z","shell.execute_reply":"2025-11-19T20:57:17.599115Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"from transformers import DataCollatorWithPadding  # Assurez-vous d'avoir cette ligne d'importation\n\n\n# CrÃ©er un Trainer\ntrainerfreezing = Trainer(\n    model=modelf,  # Utilisez le modÃ¨le DistilBERT que vous avez dÃ©fini prÃ©cÃ©demment\n    args=training_args,  # Les paramÃ¨tres d'entraÃ®nement dÃ©finis prÃ©cÃ©demment\n    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),  # GÃ¨re le padding des donnÃ©es lors de l'entraÃ®nement\n    compute_metrics=compute_metrics,  # Fonction pour calculer les mÃ©triques d'Ã©valuation\n    train_dataset=train_datasetb,  # L'ensemble de donnÃ©es d'entraÃ®nement\n    eval_dataset=test_datasetb  # L'ensemble de donnÃ©es d'Ã©valuation\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T20:57:20.757659Z","iopub.execute_input":"2025-11-19T20:57:20.757972Z","iopub.status.idle":"2025-11-19T20:57:20.903425Z","shell.execute_reply.started":"2025-11-19T20:57:20.757947Z","shell.execute_reply":"2025-11-19T20:57:20.902868Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"# EntraÃ®ner le modÃ¨le\ntrainerfreezing.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T20:57:24.630395Z","iopub.execute_input":"2025-11-19T20:57:24.631100Z","iopub.status.idle":"2025-11-19T20:58:18.114047Z","shell.execute_reply.started":"2025-11-19T20:57:24.631076Z","shell.execute_reply":"2025-11-19T20:58:18.113308Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='375' max='375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [375/375 00:52, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>100</td>\n      <td>No log</td>\n      <td>0.679781</td>\n      <td>0.536000</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>No log</td>\n      <td>0.663598</td>\n      <td>0.774000</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>No log</td>\n      <td>0.656881</td>\n      <td>0.763000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=375, training_loss=0.6693230387369792, metrics={'train_runtime': 52.9813, 'train_samples_per_second': 56.624, 'train_steps_per_second': 7.078, 'total_flos': 397402195968000.0, 'train_loss': 0.6693230387369792, 'epoch': 3.0})"},"metadata":{}}],"execution_count":44},{"cell_type":"code","source":"import torch\n\n# 1. DÃ©finir le bon pÃ©riphÃ©rique (device)\n# Sur Kaggle avec GPU, ce sera \"cuda\". Sinon \"cpu\".\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"Le modÃ¨le sera exÃ©cutÃ© sur : {device}\")\n\n# 2. Sauvegarde du modÃ¨le (inchangÃ©)\ntrainerfull.save_model(\"trainer_full\")\n\n# 3. Passer le modÃ¨le sur le bon pÃ©riphÃ©rique (cuda)\nmodel.to(device)\n\n# 4. Afficher les prÃ©dictions\nprint(\"PrÃ©dictions du modÃ¨le entraÃ®nÃ© :\")\nprint(\"---------------------------------\")\n\n# Parcourir la liste des textes Ã  prÃ©dire\nfor texte in liste_texte:\n    # Tokenizer le texte ET l'envoyer sur le mÃªme pÃ©riphÃ©rique que le modÃ¨le\n    inputs = tokenizer.encode(texte, return_tensors=\"pt\").to(device) # <--- Ici, on utilise 'device' (cuda)\n\n    # Obtenir les logits\n    with torch.no_grad(): # Optionnel mais recommandÃ© pour l'infÃ©rence (Ã©conomise la mÃ©moire)\n        logits = model(inputs).logits\n\n    # PrÃ©dire la classe\n    predictions = torch.max(logits, 1).indices\n\n    # Afficher le rÃ©sultat\n    print(texte + \" - \" + id2label[predictions.tolist()[0]])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T20:59:43.410643Z","iopub.execute_input":"2025-11-19T20:59:43.411447Z","iopub.status.idle":"2025-11-19T20:59:44.289232Z","shell.execute_reply.started":"2025-11-19T20:59:43.411410Z","shell.execute_reply":"2025-11-19T20:59:44.288356Z"}},"outputs":[{"name":"stdout","text":"Le modÃ¨le sera exÃ©cutÃ© sur : cuda\nPrÃ©dictions du modÃ¨le entraÃ®nÃ© :\n---------------------------------\nThis movie was a masterpiece. - Positif\nI was blown away by the acting. - NÃ©gatif\nIt's a classic that everyone should watch. - Positif\nThe plot was confusing and hard to follow. - NÃ©gatif\nThe special effects were top-notch. - Positif\nI couldn't stop laughing throughout the movie. - NÃ©gatif\nThe soundtrack was incredible. - Positif\nIt's a total waste of time. - NÃ©gatif\nI'm still thinking about that ending. - NÃ©gatif\nI wouldn't recommend it to anyone. - NÃ©gatif\n","output_type":"stream"}],"execution_count":46},{"cell_type":"markdown","source":"# Finetuning LoRA","metadata":{}},{"cell_type":"code","source":"# Importation des outils spÃ©cifiques aux modÃ¨les transformers\nfrom transformers import (\n    AutoTokenizer,  # Pour le tokenizing des textes\n    AutoModelForSequenceClassification,  # Pour charger un modÃ¨le prÃ©-entraÃ®nÃ© pour la classification de sÃ©quences\n    TrainingArguments,  # Pour dÃ©finir les paramÃ¨tres d'entraÃ®nement\n    Trainer,  # Pour entraÃ®ner le modÃ¨le\n    DataCollatorWithPadding  # Pour gÃ©rer le padding des sÃ©quences lors de l'entraÃ®nement\n)\n# Importation des bibliothÃ¨ques pour le fine-tuning avec PEFT (Parameter-Efficient Fine-tuning)\nfrom peft import PeftModel, PeftConfig, get_peft_model, LoraConfig","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T21:00:01.839873Z","iopub.execute_input":"2025-11-19T21:00:01.840743Z","iopub.status.idle":"2025-11-19T21:00:01.844713Z","shell.execute_reply.started":"2025-11-19T21:00:01.840710Z","shell.execute_reply":"2025-11-19T21:00:01.843770Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"# DÃ©finir le modÃ¨le que vous souhaitez utiliser pour la classification de sÃ©quences. Vous pouvez choisir un modÃ¨le prÃ©-entraÃ®nÃ©, comme 'distilbert-base-uncased' ou 'roberta-base'.\n\nmodel_checkpoint = 'distilbert-base-uncased'\n\n# GÃ©nÃ©rer un modÃ¨le de classification Ã  partir du modÃ¨le prÃ©-entraÃ®nÃ©\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    model_checkpoint, num_labels=2, id2label=id2label, label2id=label2id)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T21:00:04.927540Z","iopub.execute_input":"2025-11-19T21:00:04.927835Z","iopub.status.idle":"2025-11-19T21:00:05.139832Z","shell.execute_reply.started":"2025-11-19T21:00:04.927812Z","shell.execute_reply":"2025-11-19T21:00:05.139067Z"}},"outputs":[{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":48},{"cell_type":"code","source":"# display architecture\nmodel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T21:00:08.119029Z","iopub.execute_input":"2025-11-19T21:00:08.119318Z","iopub.status.idle":"2025-11-19T21:00:08.125419Z","shell.execute_reply.started":"2025-11-19T21:00:08.119297Z","shell.execute_reply":"2025-11-19T21:00:08.124724Z"}},"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"DistilBertForSequenceClassification(\n  (distilbert): DistilBertModel(\n    (embeddings): Embeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (transformer): Transformer(\n      (layer): ModuleList(\n        (0-5): 6 x TransformerBlock(\n          (attention): DistilBertSdpaAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n            (activation): GELUActivation()\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n      )\n    )\n  )\n  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n  (classifier): Linear(in_features=768, out_features=2, bias=True)\n  (dropout): Dropout(p=0.2, inplace=False)\n)"},"metadata":{}}],"execution_count":49},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"# CrÃ©er un tokenizer pour le modÃ¨le\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint, add_prefix_space=True)\ntokenizer.pad_token\n# Ajouter un jeton de padding s'il n'existe pas\nif tokenizer.pad_token is None:\n    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n    model.resize_token_embeddings(len(tokenizer))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T21:00:11.996363Z","iopub.execute_input":"2025-11-19T21:00:11.997041Z","iopub.status.idle":"2025-11-19T21:00:12.266424Z","shell.execute_reply.started":"2025-11-19T21:00:11.997006Z","shell.execute_reply":"2025-11-19T21:00:12.265359Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"# CrÃ©er une fonction pour tokenizer les donnÃ©es\ndef tokenize_function(examples):\n    text = examples[\"review\"]\n    tokenizer.truncation_side = \"left\"\n    tokenized_inputs = tokenizer(\n        text,\n        padding=True,  # Ajout du padding directement ici\n        truncation=True,\n        max_length=512\n    )\n    return tokenized_inputs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T21:00:14.852313Z","iopub.execute_input":"2025-11-19T21:00:14.853092Z","iopub.status.idle":"2025-11-19T21:00:14.857477Z","shell.execute_reply.started":"2025-11-19T21:00:14.853068Z","shell.execute_reply":"2025-11-19T21:00:14.856577Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"# Tokenizer les ensembles d'entraÃ®nement et de test\n# CrÃ©er un DatasetDict\n# Tokenizer les ensembles d'entraÃ®nement et de test et crÃ©er un DatasetDict\ndataset = DatasetDict({\n    'train': train_dataset,\n    'test': test_dataset\n})\n\ntokenized_dataset = dataset.map(tokenize_function, batched=True)\n\ntokenized_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T21:00:17.287404Z","iopub.execute_input":"2025-11-19T21:00:17.288013Z","iopub.status.idle":"2025-11-19T21:00:18.525568Z","shell.execute_reply.started":"2025-11-19T21:00:17.287986Z","shell.execute_reply":"2025-11-19T21:00:18.524884Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd6a57eccc4149d0bf6eb14503753132"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f6af2f948bf457696406460334826df"}},"metadata":{}},{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['review', 'label', '__index_level_0__', 'input_ids', 'attention_mask'],\n        num_rows: 1000\n    })\n    test: Dataset({\n        features: ['review', 'label', '__index_level_0__', 'input_ids', 'attention_mask'],\n        num_rows: 1000\n    })\n})"},"metadata":{}}],"execution_count":52},{"cell_type":"code","source":"# CrÃ©er un DataCollator pour gÃ©rer le padding\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T21:00:21.849291Z","iopub.execute_input":"2025-11-19T21:00:21.850102Z","iopub.status.idle":"2025-11-19T21:00:21.854014Z","shell.execute_reply.started":"2025-11-19T21:00:21.850068Z","shell.execute_reply":"2025-11-19T21:00:21.853205Z"}},"outputs":[],"execution_count":53},{"cell_type":"markdown","source":"# Evaluation du modÃ¨le","metadata":{}},{"cell_type":"code","source":"# Configuration du modÃ¨le LoRA (Low-Rank Adaptation) pour le fine-tuning\n\n# Type de tÃ¢che, ici \"SEQ_CLS\" signifie classification de sÃ©quences\npeft_config = LoraConfig(\n    task_type=\"SEQ_CLS\",  # Type de tÃ¢che du modÃ¨le\n\n    # Facteur de rÃ©gularisation \"r\" pour LoRA\n    r=4,\n\n    # ParamÃ¨tre d'alpha pour LoRA, contrÃ´lant l'importance de la rÃ©gularisation LoRA\n    lora_alpha=32,\n\n    # Taux de dropout pour LoRA, qui dÃ©termine la probabilitÃ© de dÃ©sactivation alÃ©atoire des connexions\n    lora_dropout=0.01,\n\n    # Modules cibles pour l'application de la rÃ©gularisation LoRA, ici uniquement le module 'q_lin' est ciblÃ©\n    target_modules=['q_lin']\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T21:00:24.209047Z","iopub.execute_input":"2025-11-19T21:00:24.209326Z","iopub.status.idle":"2025-11-19T21:00:24.213282Z","shell.execute_reply.started":"2025-11-19T21:00:24.209305Z","shell.execute_reply":"2025-11-19T21:00:24.212510Z"}},"outputs":[],"execution_count":54},{"cell_type":"code","source":"peft_config","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T21:00:27.549457Z","iopub.execute_input":"2025-11-19T21:00:27.550053Z","iopub.status.idle":"2025-11-19T21:00:27.555085Z","shell.execute_reply.started":"2025-11-19T21:00:27.550027Z","shell.execute_reply":"2025-11-19T21:00:27.554405Z"}},"outputs":[{"execution_count":55,"output_type":"execute_result","data":{"text/plain":"LoraConfig(task_type='SEQ_CLS', peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path=None, revision=None, inference_mode=False, r=4, target_modules={'q_lin'}, exclude_modules=None, lora_alpha=32, lora_dropout=0.01, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', trainable_token_indices=None, loftq_config={}, eva_config=None, corda_config=None, use_dora=False, use_qalora=False, qalora_group_size=16, layer_replication=None, runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=False), lora_bias=False)"},"metadata":{}}],"execution_count":55},{"cell_type":"code","source":"model = get_peft_model(model, peft_config)\nmodel.print_trainable_parameters()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T21:00:30.819776Z","iopub.execute_input":"2025-11-19T21:00:30.820552Z","iopub.status.idle":"2025-11-19T21:00:30.842163Z","shell.execute_reply.started":"2025-11-19T21:00:30.820513Z","shell.execute_reply":"2025-11-19T21:00:30.841222Z"}},"outputs":[{"name":"stdout","text":"trainable params: 628,994 || all params: 67,584,004 || trainable%: 0.9307\n","output_type":"stream"}],"execution_count":56},{"cell_type":"code","source":"# HyperparamÃ¨tres\n\n# Taux d'apprentissage (learning rate) - C'est la vitesse Ã  laquelle le modÃ¨le apprend\nlr = 1e-3\n\n# Taille du lot (batch size) - Le nombre d'exemples de donnÃ©es utilisÃ©s pour chaque mise Ã  jour de poids du modÃ¨le\nbatch_size = 4\n\n# Nombre d'Ã©poques (epochs) - Le nombre de fois que le modÃ¨le parcourt l'ensemble de donnÃ©es complet lors de l'entraÃ®nement\nnum_epochs = 3","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T21:00:33.231067Z","iopub.execute_input":"2025-11-19T21:00:33.231687Z","iopub.status.idle":"2025-11-19T21:00:33.235497Z","shell.execute_reply.started":"2025-11-19T21:00:33.231657Z","shell.execute_reply":"2025-11-19T21:00:33.234600Z"}},"outputs":[],"execution_count":57},{"cell_type":"code","source":"# DÃ©finition des arguments d'entraÃ®nement\n\n# RÃ©pertoire de sortie oÃ¹ les rÃ©sultats de l'entraÃ®nement seront sauvegardÃ©s\ntraining_args = TrainingArguments(\n    output_dir= model_checkpoint + \"-lora-text-classification\",  # Chemin du rÃ©pertoire de sortie\n\n    # Taux d'apprentissage\n    learning_rate=lr,\n\n    # Taille du lot\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n\n    # Nombre d'Ã©poques\n    num_train_epochs=num_epochs,\n\n    # Terme de rÃ©gularisation\n    weight_decay=0.01,\n\n    # --- CORRECTION ICI ---\n    # StratÃ©gie d'Ã©valuation (nouveau nom)\n    eval_strategy=\"epoch\",\n\n    # StratÃ©gie de sauvegarde\n    save_strategy=\"epoch\",\n\n    # Charger le meilleur modÃ¨le\n    load_best_model_at_end=True,\n    \n    # Et toujours pour Ã©viter le crash wandb\n    report_to=\"none\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T21:10:51.590639Z","iopub.execute_input":"2025-11-19T21:10:51.590999Z","iopub.status.idle":"2025-11-19T21:10:51.617295Z","shell.execute_reply.started":"2025-11-19T21:10:51.590967Z","shell.execute_reply":"2025-11-19T21:10:51.616729Z"}},"outputs":[],"execution_count":59},{"cell_type":"code","source":"# CrÃ©ation de l'objet \"trainer\" pour entraÃ®ner le modÃ¨le\n\n# Le modÃ¨le Ã  entraÃ®ner\ntrainer = Trainer(\n    model=model,  # Le modÃ¨le que vous avez configurÃ© prÃ©cÃ©demment\n\n    # Les arguments d'entraÃ®nement dÃ©finis prÃ©cÃ©demment\n    args=training_args,\n\n    # L'ensemble de donnÃ©es d'entraÃ®nement tokenisÃ©\n    train_dataset=tokenized_dataset[\"train\"],\n\n    # L'ensemble de donnÃ©es de validation tokenisÃ©\n    eval_dataset=tokenized_dataset[\"test\"],\n\n    # Le tokenizer utilisÃ© pour le prÃ©traitement\n    tokenizer=tokenizer,\n\n    # Le \"data_collator\" qui gÃ¨re le padding dynamique des exemples dans chaque lot pour qu'ils aient la mÃªme longueur\n    data_collator=data_collator,\n\n    # La fonction de calcul des mÃ©triques pour Ã©valuer le modÃ¨le\n    compute_metrics=compute_metrics\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T21:10:55.033596Z","iopub.execute_input":"2025-11-19T21:10:55.034244Z","iopub.status.idle":"2025-11-19T21:10:55.147815Z","shell.execute_reply.started":"2025-11-19T21:10:55.034218Z","shell.execute_reply":"2025-11-19T21:10:55.147190Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_48/2241369498.py:4: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n","output_type":"stream"}],"execution_count":60},{"cell_type":"code","source":"# EntraÃ®nement du modÃ¨le\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T21:10:58.573888Z","iopub.execute_input":"2025-11-19T21:10:58.574569Z","iopub.status.idle":"2025-11-19T21:13:33.959295Z","shell.execute_reply.started":"2025-11-19T21:10:58.574547Z","shell.execute_reply":"2025-11-19T21:13:33.958633Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='750' max='750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [750/750 02:34, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.540867</td>\n      <td>0.885000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.329300</td>\n      <td>0.586220</td>\n      <td>0.875000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.329300</td>\n      <td>0.648329</td>\n      <td>0.883000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":61,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=750, training_loss=0.2689953816731771, metrics={'train_runtime': 154.9282, 'train_samples_per_second': 19.364, 'train_steps_per_second': 4.841, 'total_flos': 403199004672000.0, 'train_loss': 0.2689953816731771, 'epoch': 3.0})"},"metadata":{}}],"execution_count":61},{"cell_type":"markdown","source":"# Generate prediction","metadata":{}},{"cell_type":"code","source":"import torch\n\n# 1. DÃ©finir le bon pÃ©riphÃ©rique (device)\n# Sur Kaggle avec GPU, ce sera \"cuda\". Sinon \"cpu\".\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"Le modÃ¨le sera exÃ©cutÃ© sur : {device}\")\n\n# 2. Sauvegarde du modÃ¨le (inchangÃ©)\ntrainerfull.save_model(\"trainer_full\")\n\n# 3. Passer le modÃ¨le sur le bon pÃ©riphÃ©rique (cuda)\nmodel.to(device)\n\n# 4. Afficher les prÃ©dictions\nprint(\"PrÃ©dictions du modÃ¨le entraÃ®nÃ© :\")\nprint(\"---------------------------------\")\n\n# Parcourir la liste des textes Ã  prÃ©dire\nfor texte in liste_texte:\n    # Tokenizer le texte ET l'envoyer sur le mÃªme pÃ©riphÃ©rique que le modÃ¨le\n    inputs = tokenizer.encode(texte, return_tensors=\"pt\").to(device) # <--- Ici, on utilise 'device' (cuda)\n\n    # Obtenir les logits\n    with torch.no_grad(): # Optionnel mais recommandÃ© pour l'infÃ©rence (Ã©conomise la mÃ©moire)\n        logits = model(inputs).logits\n\n    # PrÃ©dire la classe\n    predictions = torch.max(logits, 1).indices\n\n    # Afficher le rÃ©sultat\n    print(texte + \" - \" + id2label[predictions.tolist()[0]])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T21:13:34.890012Z","iopub.execute_input":"2025-11-19T21:13:34.890260Z","iopub.status.idle":"2025-11-19T21:13:35.832791Z","shell.execute_reply.started":"2025-11-19T21:13:34.890237Z","shell.execute_reply":"2025-11-19T21:13:35.832108Z"}},"outputs":[{"name":"stdout","text":"Le modÃ¨le sera exÃ©cutÃ© sur : cuda\nPrÃ©dictions du modÃ¨le entraÃ®nÃ© :\n---------------------------------\nThis movie was a masterpiece. - Positif\nI was blown away by the acting. - NÃ©gatif\nIt's a classic that everyone should watch. - Positif\nThe plot was confusing and hard to follow. - NÃ©gatif\nThe special effects were top-notch. - Positif\nI couldn't stop laughing throughout the movie. - NÃ©gatif\nThe soundtrack was incredible. - Positif\nIt's a total waste of time. - NÃ©gatif\nI'm still thinking about that ending. - NÃ©gatif\nI wouldn't recommend it to anyone. - NÃ©gatif\n","output_type":"stream"}],"execution_count":63}]}