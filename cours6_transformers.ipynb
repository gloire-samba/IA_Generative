{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Comprendre les mécanismes d'attention"
      ],
      "metadata": {
        "id": "k0QxBUppg4fP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iqpcme4-Jjgk"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialisation\n",
        "sentence = \"Quel temps fait-il\"\n",
        "embedding_layer = tf.keras.layers.Embedding(5000, 256)\n",
        "tokenized_sentence = [15, 120, 260, 45]  # Tokenisation arbitraire pour l'exemple\n",
        "embedded_sentence = embedding_layer(tf.convert_to_tensor([tokenized_sentence]))\n",
        "print(\"Dimension de l'embedding de la phrase:\", embedded_sentence.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8l5uHGeshMXM",
        "outputId": "d0f39aab-f3fe-4fc7-c847-66a7c64abdf2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimension de l'embedding de la phrase: (1, 4, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encodeur\n",
        "## Calcul des Query, Key, Value\n",
        "Q_enc = tf.keras.layers.Dense(256)(embedded_sentence)\n",
        "K_enc = tf.keras.layers.Dense(256)(embedded_sentence)\n",
        "V_enc = tf.keras.layers.Dense(256)(embedded_sentence)\n",
        "print(\"\\nEncodeur:\")\n",
        "print(\"Dimension de Q:\", Q_enc.shape)\n",
        "print(\"Dimension de K:\", K_enc.shape)\n",
        "print(\"Dimension de V:\", V_enc.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxHzPeTOhP6P",
        "outputId": "195ed750-d077-4956-9f11-dd7a809458f0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Encodeur:\n",
            "Dimension de Q: (1, 4, 256)\n",
            "Dimension de K: (1, 4, 256)\n",
            "Dimension de V: (1, 4, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Attention\n",
        "QK_enc = tf.matmul(Q_enc, K_enc, transpose_b=True)\n",
        "QK_normalized_enc = QK_enc / tf.math.sqrt(tf.cast(256, tf.float32))\n",
        "softmax_enc = tf.nn.softmax(QK_normalized_enc)\n",
        "attention_enc = tf.matmul(softmax_enc, V_enc)\n",
        "print(\"Dimension de l'attention:\", attention_enc.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2yjMc5RhTK5",
        "outputId": "05c81227-2205-4213-d09c-cc7ce53e374b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimension de l'attention: (1, 4, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Décodeur (pour prédire le prochain mot)\n",
        "## Utilisez l'état du dernier mot comme Query\n",
        "Q_dec = Q_enc[:, -1, :]\n",
        "print(\"\\nDécodeur:\")\n",
        "print(\"Dimension de Q (décodeur):\", Q_dec.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T82hIGIthXiB",
        "outputId": "a06fa19a-9c13-4788-b585-7e754ca8bf2f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Décodeur:\n",
            "Dimension de Q (décodeur): (1, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Attention\n",
        "QK_dec = tf.matmul(tf.expand_dims(Q_dec, 1), K_enc, transpose_b=True)\n",
        "QK_normalized_dec = QK_dec / tf.math.sqrt(tf.cast(256, tf.float32))\n",
        "softmax_dec = tf.nn.softmax(QK_normalized_dec)\n",
        "attention_dec = tf.matmul(softmax_dec, V_enc)\n",
        "print(\"Dimension de l'attention (décodeur):\", attention_dec.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIIsbTB_hbFy",
        "outputId": "dd274007-973c-4d9d-fa6e-531580efc7fe"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimension de l'attention (décodeur): (1, 1, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sortie: prédiction du prochain mot\n",
        "output = tf.keras.layers.Dense(5000, activation='softmax')(attention_dec)\n",
        "print(\"\\nDimension de la sortie:\", output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUIeullQhezc",
        "outputId": "c13d584d-16c4-41d3-894b-ea8c78b11f94"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dimension de la sortie: (1, 1, 5000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prédire le mot avec l'indice le plus élevé comme mot suivant\n",
        "predicted_next_word_index = tf.argmax(output, axis=-1)\n",
        "print(\"Index du mot prédit:\", predicted_next_word_index.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yxex04a5hiP1",
        "outputId": "b52102f0-5a91-49af-d7f7-f925ab8f0f07"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index du mot prédit: [[236]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multihead Attention"
      ],
      "metadata": {
        "id": "sJDF6AUghmzT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import math"
      ],
      "metadata": {
        "id": "sJVoqQ7EhqO4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_heads(x, num_heads):\n",
        "    \"\"\"Divise les dernières dimensions de x en (num_heads, depth).\"\"\"\n",
        "    batch_size = tf.shape(x)[0]\n",
        "    d_model = x.shape[-1]\n",
        "    depth = d_model // num_heads\n",
        "\n",
        "    reshaped_x = tf.reshape(x, (batch_size, -1, num_heads, depth))\n",
        "    return tf.transpose(reshaped_x, perm=[0, 2, 1, 3])\n",
        "\n",
        "def multi_head_attention(Q, K, V, num_heads):\n",
        "    \"\"\"Implémentation de la multi-head attention.\"\"\"\n",
        "    d_model = Q.shape[-1]\n",
        "    depth = d_model // num_heads\n",
        "\n",
        "    # Divise en plusieurs têtes\n",
        "    Q = split_heads(Q, num_heads)\n",
        "    K = split_heads(K, num_heads)\n",
        "    V = split_heads(V, num_heads)\n",
        "\n",
        "    # Calcul de l'attention pour chaque tête\n",
        "    QK = tf.matmul(Q, K, transpose_b=True)\n",
        "    QK_normalized = QK / tf.math.sqrt(tf.cast(depth, tf.float32))\n",
        "    softmax_weights = tf.nn.softmax(QK_normalized, axis=-1)\n",
        "    attention = tf.matmul(softmax_weights, V)\n",
        "\n",
        "    # Concatène les têtes et applique une transformation linéaire\n",
        "    attention_concatenated = tf.transpose(attention, perm=[0, 2, 1, 3])\n",
        "    concatenated = tf.reshape(attention_concatenated, (tf.shape(attention)[0], -1, d_model))\n",
        "    return tf.keras.layers.Dense(d_model)(concatenated)"
      ],
      "metadata": {
        "id": "Ozq6s0jshw1b"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialisation\n",
        "sentence = \"Le ciel est\"\n",
        "embedding_layer = tf.keras.layers.Embedding(5000, 256)\n",
        "tokenized_sentence = [10, 100, 150]\n",
        "embedded_sentence = embedding_layer(tf.convert_to_tensor([tokenized_sentence]))\n",
        "print(\"Dimension de l'embedding de la phrase:\", embedded_sentence.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UYDC0a-h08d",
        "outputId": "ae73d4b8-f70b-47ad-a285-cc00f5dca292"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimension de l'embedding de la phrase: (1, 3, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encodeur avec multi-head attention\n",
        "## Calcul des Query, Key, Value\n",
        "Q_enc = tf.keras.layers.Dense(256)(embedded_sentence)\n",
        "K_enc = tf.keras.layers.Dense(256)(embedded_sentence)\n",
        "V_enc = tf.keras.layers.Dense(256)(embedded_sentence)\n",
        "\n",
        "## Multi-head attention\n",
        "attention_enc = multi_head_attention(Q_enc, K_enc, V_enc, 8)\n",
        "print(\"\\nEncodeur:\")\n",
        "print(\"Dimension après multi-head attention:\", attention_enc.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44kJ_kKUh4Yp",
        "outputId": "f2d5539f-5bb4-43cd-c64d-420875f86d2d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Encodeur:\n",
            "Dimension après multi-head attention: (1, 3, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Décodeur avec multi-head attention\n",
        "## Utiliser l'état du dernier mot comme Query\n",
        "Q_dec = Q_enc[:, -1, :]\n",
        "K_dec = K_enc\n",
        "V_dec = V_enc\n",
        "\n",
        "## Multi-head attention\n",
        "attention_dec = multi_head_attention(tf.expand_dims(Q_dec, 1), K_dec, V_dec, 8)\n",
        "print(\"\\nDécodeur:\")\n",
        "print(\"Dimension de l'attention multi-tête (décodeur):\", attention_dec.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jtpm-1f5h8rG",
        "outputId": "64fd01d2-efc9-4b30-f18d-3b778b028d89"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Décodeur:\n",
            "Dimension de l'attention multi-tête (décodeur): (1, 1, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sortie: prédiction du prochain mot\n",
        "output = tf.keras.layers.Dense(5000, activation='softmax')(attention_dec)\n",
        "print(\"\\nDimension de la sortie:\", output.shape)\n",
        "\n",
        "# Prédire le mot avec l'indice le plus élevé comme mot suivant\n",
        "predicted_next_word_index = tf.argmax(output, axis=-1)\n",
        "print(\"Index du mot prédit:\", predicted_next_word_index.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHvCd0oMiBa7",
        "outputId": "3dab294e-b64c-4abe-e67c-d32e92faa71d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dimension de la sortie: (1, 1, 5000)\n",
            "Index du mot prédit: [[1679]]\n"
          ]
        }
      ]
    }
  ]
}